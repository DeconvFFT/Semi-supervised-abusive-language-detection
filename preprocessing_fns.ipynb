{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88fc34af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install emoji\n",
    "# !pip install pandas\n",
    "# !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54b1ff62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from scipy.sparse import csr_matrix\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ad2fd7d",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      id                                              tweet subtask_a  \\\n",
       "0  86426  @USER She should ask a few native Americans wh...       OFF   \n",
       "1  90194  @USER @USER Go home youâ€™re drunk!!! @USER #MAG...       OFF   \n",
       "2  16820  Amazon is investigating Chinese employees who ...       NOT   \n",
       "3  62688  @USER Someone should'veTaken\" this piece of sh...       OFF   \n",
       "4  43605  @USER @USER Obama wanted liberals &amp; illega...       NOT   \n",
       "\n",
       "  subtask_b subtask_c  \n",
       "0       UNT       NaN  \n",
       "1       TIN       IND  \n",
       "2       NaN       NaN  \n",
       "3       UNT       NaN  \n",
       "4       NaN       NaN  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>tweet</th>\n      <th>subtask_a</th>\n      <th>subtask_b</th>\n      <th>subtask_c</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>86426</td>\n      <td>@USER She should ask a few native Americans wh...</td>\n      <td>OFF</td>\n      <td>UNT</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>90194</td>\n      <td>@USER @USER Go home youâ€™re drunk!!! @USER #MAG...</td>\n      <td>OFF</td>\n      <td>TIN</td>\n      <td>IND</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>16820</td>\n      <td>Amazon is investigating Chinese employees who ...</td>\n      <td>NOT</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>62688</td>\n      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n      <td>OFF</td>\n      <td>UNT</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>43605</td>\n      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n      <td>NOT</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/OLIDv1/olid-training-v1.0.tsv\", sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd8d7b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "def emoji_to_text(s):\n",
    "    s = emoji.demojize(s)\n",
    "    s = s.replace(':',' ')\n",
    "    s = s.replace('_',' ')    \n",
    "    s = ' '.join(s.split())\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fd87858",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'@USER He is all grown up loudly crying face loudly crying face loudly crying face'"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "s = '@USER He is all grown upðŸ˜­ðŸ˜­ðŸ˜­'\n",
    "emoji_to_text(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "018fb825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "slang_df = pd.read_csv('data/twitterSlang.csv')\n",
    "slang_dict = dict(zip(slang_df.slang, slang_df.formal_translation))\n",
    "\n",
    "def fix_slang(s):\n",
    "    s_list = s.split()\n",
    "    new_s_list = []\n",
    "    for word in s_list:\n",
    "        if word in slang_dict.keys():\n",
    "            new_s_list.append(slang_dict[word])\n",
    "        else:\n",
    "            new_s_list.append(word)\n",
    "            \n",
    "    return ' '.join(new_s_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b01e3f4",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"I'll fix this as soon as possible\""
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "s = \"I'll fix this asap\"\n",
    "fix_slang(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6669f52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sent, lemmatizer, stop_words):\n",
    "    \n",
    "    alphabet = \"abcdefghijklmnopqrstuvwxyz 0123456789',.\"\n",
    "    sent = sent.lower()\n",
    "    sent = sent.replace('@user','')\n",
    "    sent = sent.replace('@[\\w\\-]+','')\n",
    "\n",
    "    cleaned_sent_list = [char if char in alphabet else ' ' for char in sent] # remove all tags not in the alphabet\n",
    "\n",
    "    cleaned_sent = ''.join(cleaned_sent_list)\n",
    "    cleaned_sent_list = [lemmatizer.lemmatize(token) for token in cleaned_sent.split(\" \")]\n",
    "    cleaned_sent_list = [word for word in cleaned_sent_list if not word in stop_words]\n",
    "    cleaned_sent = ' '.join(cleaned_sent_list)\n",
    "    cleaned_sent = cleaned_sent.replace(\"n't\",' not') # replace words like \"isn't\" with \"is not\"\n",
    "    cleaned_sent = ' . '.join([x for x in cleaned_sent.split('.') if len(x)>0]) # remove multiple periods, and add spaces before and after a period\n",
    "    cleaned_sent = ' , '.join([x for x in cleaned_sent.split(',') if len(x)>0]) # add spaces before and after a comma\n",
    "    cleaned_sent = ' '.join(cleaned_sent.split()) # remove multiple spaces\n",
    "    return cleaned_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27d307af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sent):\n",
    "    alphabet = \"abcdefghijklmnopqrstuvwxyz 0123456789',.\"\n",
    "    sent = sent.lower() \n",
    "    sent = cleanhtml(sent) # remove html tags \n",
    "    cleaned_sent_list = [char if char in alphabet else ' ' for char in sent] # remove all tags not in the alphabet\n",
    "    cleaned_sent = ''.join(cleaned_sent_list)\n",
    "    cleaned_sent = cleaned_sent.replace(\"n't\",' not') # replace words like \"isn't\" with \"is not\"\n",
    "    cleaned_sent = ' . '.join([x for x in cleaned_sent.split('.') if len(x)>0]) # remove multiple periods, and add spaces before and after a period\n",
    "    cleaned_sent = ' , '.join([x for x in cleaned_sent.split(',') if len(x)>0]) # add spaces before and after a comma\n",
    "    cleaned_sent = ' '.join(cleaned_sent.split()) # remove multiple spaces\n",
    "    return cleaned_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac17636",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python397jvsc74a57bd0f1cd6fa187f75416e22a91ec71c95b3d72c0eb3110f2cc060653dcaa47999e2a",
   "display_name": "Python 3.9.7 64-bit ('tfnlp': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "metadata": {
   "interpreter": {
    "hash": "f1cd6fa187f75416e22a91ec71c95b3d72c0eb3110f2cc060653dcaa47999e2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
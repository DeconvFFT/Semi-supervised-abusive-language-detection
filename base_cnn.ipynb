{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ac4b1a",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 1,
     "id": "e8ac4b1a",
     "kernelId": "3e6e40d8-69f5-4d5b-bd6d-76c6f49146ca"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (1.3.4)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (1.19.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (1.0.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.19.4)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.4.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (3.0.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23efbf50-c36e-4f29-9527-eb76bc6fec25",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 2,
     "id": "23efbf50-c36e-4f29-9527-eb76bc6fec25",
     "kernelId": "3e6e40d8-69f5-4d5b-bd6d-76c6f49146ca"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from scipy.sparse import csr_matrix\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.layers import Embedding,Dense,Dropout,Bidirectional,GlobalMaxPool1D,GlobalAveragePooling1D, SpatialDropout1D,Input,Conv1D,MaxPooling1D,Flatten\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from sklearn.utils import class_weight\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import pandas as pd\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84e7e8c-0390-4326-b83c-0feea1fc537f",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 3,
     "id": "d84e7e8c-0390-4326-b83c-0feea1fc537f",
     "kernelId": "3e6e40d8-69f5-4d5b-bd6d-76c6f49146ca"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>subtask_a</th>\n",
       "      <th>subtask_b</th>\n",
       "      <th>subtask_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86426</td>\n",
       "      <td>@USER She should ask a few native Americans wh...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90194</td>\n",
       "      <td>@USER @USER Go home you’re drunk!!! @USER #MAG...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>TIN</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16820</td>\n",
       "      <td>Amazon is investigating Chinese employees who ...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62688</td>\n",
       "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
       "      <td>OFF</td>\n",
       "      <td>UNT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43605</td>\n",
       "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
       "      <td>NOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet subtask_a  \\\n",
       "0  86426  @USER She should ask a few native Americans wh...       OFF   \n",
       "1  90194  @USER @USER Go home you’re drunk!!! @USER #MAG...       OFF   \n",
       "2  16820  Amazon is investigating Chinese employees who ...       NOT   \n",
       "3  62688  @USER Someone should'veTaken\" this piece of sh...       OFF   \n",
       "4  43605  @USER @USER Obama wanted liberals &amp; illega...       NOT   \n",
       "\n",
       "  subtask_b subtask_c  \n",
       "0       UNT       NaN  \n",
       "1       TIN       IND  \n",
       "2       NaN       NaN  \n",
       "3       UNT       NaN  \n",
       "4       NaN       NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/OLIDv1/olid-training-v1.0.tsv\", sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43727f4e-645a-4622-b79a-ff14719e3547",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 4,
     "id": "43727f4e-645a-4622-b79a-ff14719e3547",
     "kernelId": "3e6e40d8-69f5-4d5b-bd6d-76c6f49146ca"
    }
   },
   "outputs": [],
   "source": [
    "# Reference: https://stackoverflow.com/questions/9662346/python-code-to-remove-html-tags-from-a-string\n",
    "CLEANR = re.compile('<.*?>') \n",
    "def cleanhtml(raw_html):\n",
    "    cleantext = re.sub(CLEANR, '', raw_html)\n",
    "    return cleantext\n",
    "\n",
    "def preprocess(sent):\n",
    "    alphabet = \"abcdefghijklmnopqrstuvwxyz 0123456789',.\"\n",
    "    sent = sent.lower() \n",
    "    sent = cleanhtml(sent) # remove html tags \n",
    "    cleaned_sent_list = [char if char in alphabet else ' ' for char in sent] # remove all tags not in the alphabet\n",
    "    cleaned_sent = ''.join(cleaned_sent_list)\n",
    "    cleaned_sent = cleaned_sent.replace(\"n't\",' not') # replace words like \"isn't\" with \"is not\"\n",
    "    cleaned_sent = ' . '.join([x for x in cleaned_sent.split('.') if len(x)>0]) # remove multiple periods, and add spaces before and after a period\n",
    "    cleaned_sent = ' , '.join([x for x in cleaned_sent.split(',') if len(x)>0]) # add spaces before and after a comma\n",
    "    cleaned_sent = ' '.join(cleaned_sent.split()) # remove multiple spaces\n",
    "    return cleaned_sent\n",
    "\n",
    "def print_metrics(y,y_p):\n",
    "    print('Accuracy:',accuracy_score(y,y_p))\n",
    "    print('Precision:',precision_score(y,y_p))\n",
    "    print('Recall:',recall_score(y,y_p))\n",
    "    print('F1 score:',f1_score(y,y_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9373eeb",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "f9373eeb",
     "kernelId": "3e6e40d8-69f5-4d5b-bd6d-76c6f49146ca"
    }
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b77e134-3e72-4c5a-a0f6-3132285c8224",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 5,
     "id": "1b77e134-3e72-4c5a-a0f6-3132285c8224",
     "kernelId": "3e6e40d8-69f5-4d5b-bd6d-76c6f49146ca"
    }
   },
   "outputs": [],
   "source": [
    "x = df.tweet\n",
    "y = df.subtask_a.apply(lambda x: 1 if x=='OFF' else 0)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8846df",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 6,
     "id": "2f8846df",
     "kernelId": "3e6e40d8-69f5-4d5b-bd6d-76c6f49146ca"
    }
   },
   "outputs": [],
   "source": [
    "data_train = [preprocess(tweet) for tweet in x_train]\n",
    "data_val = [preprocess(tweet) for tweet in x_val]\n",
    "\n",
    "n_features = 500\n",
    "vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(1,3),max_features=n_features)\n",
    "X_train = vectorizer.fit_transform(data_train)\n",
    "X_val = vectorizer.transform(data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548b7573",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 7,
     "id": "548b7573",
     "kernelId": "3e6e40d8-69f5-4d5b-bd6d-76c6f49146ca"
    }
   },
   "outputs": [],
   "source": [
    "X_train = X_train.toarray().reshape([-1,n_features,1])\n",
    "X_val = X_val.toarray().reshape([-1,n_features,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b438b45",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 8,
     "id": "6b438b45",
     "kernelId": "3e6e40d8-69f5-4d5b-bd6d-76c6f49146ca"
    }
   },
   "outputs": [],
   "source": [
    "def model_cnn(n_features=500):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Conv1D(filters=128, kernel_size=5, strides=5, activation='relu', input_shape=(n_features,1)))\n",
    "    model.add(tf.keras.layers.Conv1D(filters=128, kernel_size=5, strides=5, activation='relu'))\n",
    "    model.add(tf.keras.layers.Conv1D(filters=128, kernel_size=5, strides=5, activation='relu'))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b4d7c0",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 9,
     "id": "08b4d7c0",
     "kernelId": "3e6e40d8-69f5-4d5b-bd6d-76c6f49146ca"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-06 18:09:04.794786: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-06 18:09:04.806050: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-06 18:09:04.807039: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-06 18:09:04.809221: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-06 18:09:04.810171: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-06 18:09:04.811037: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-06 18:09:05.665074: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-06 18:09:05.666025: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-06 18:09:05.666912: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-06 18:09:05.667731: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14817 MB memory:  -> device: 0, name: Quadro RTX 5000, pci bus id: 0000:00:05.0, compute capability: 7.5\n",
      "2021-12-06 18:09:06.161435: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-06 18:09:07.779519: I tensorflow/stream_executor/cuda/cuda_dnn.cc:381] Loaded cuDNN version 8204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 4s 15ms/step - loss: 0.6412 - accuracy: 0.6644 - val_loss: 0.6308 - val_accuracy: 0.6644\n",
      "Epoch 2/25\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.6173 - accuracy: 0.6713 - val_loss: 0.6053 - val_accuracy: 0.6805\n",
      "Epoch 3/25\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.5879 - accuracy: 0.7074 - val_loss: 0.5757 - val_accuracy: 0.7183\n",
      "Epoch 4/25\n",
      "37/37 [==============================] - 0s 7ms/step - loss: 0.5599 - accuracy: 0.7265 - val_loss: 0.5812 - val_accuracy: 0.7195\n",
      "Epoch 5/25\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.5459 - accuracy: 0.7352 - val_loss: 0.5675 - val_accuracy: 0.7246\n",
      "Epoch 6/25\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.5347 - accuracy: 0.7394 - val_loss: 0.5610 - val_accuracy: 0.7243\n",
      "Epoch 7/25\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.5283 - accuracy: 0.7414 - val_loss: 0.5682 - val_accuracy: 0.7271\n",
      "Epoch 8/25\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.5191 - accuracy: 0.7501 - val_loss: 0.5651 - val_accuracy: 0.7208\n",
      "Epoch 9/25\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.5104 - accuracy: 0.7532 - val_loss: 0.5712 - val_accuracy: 0.7231\n",
      "Epoch 10/25\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.5034 - accuracy: 0.7597 - val_loss: 0.5842 - val_accuracy: 0.7273\n",
      "Epoch 11/25\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.4949 - accuracy: 0.7637 - val_loss: 0.5744 - val_accuracy: 0.7034\n",
      "Epoch 12/25\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.4849 - accuracy: 0.7729 - val_loss: 0.5845 - val_accuracy: 0.7241\n",
      "Epoch 13/25\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.4771 - accuracy: 0.7747 - val_loss: 0.5877 - val_accuracy: 0.7017\n",
      "Epoch 14/25\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.4590 - accuracy: 0.7909 - val_loss: 0.6058 - val_accuracy: 0.7130\n",
      "Epoch 15/25\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.4565 - accuracy: 0.7891 - val_loss: 0.6082 - val_accuracy: 0.7178\n",
      "Epoch 16/25\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.4315 - accuracy: 0.8077 - val_loss: 0.6218 - val_accuracy: 0.6979\n",
      "Epoch 17/25\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.4116 - accuracy: 0.8173 - val_loss: 0.6430 - val_accuracy: 0.7027\n",
      "Epoch 18/25\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.3918 - accuracy: 0.8284 - val_loss: 0.6806 - val_accuracy: 0.6916\n",
      "Epoch 19/25\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.3780 - accuracy: 0.8347 - val_loss: 0.6934 - val_accuracy: 0.7100\n",
      "Epoch 20/25\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.3603 - accuracy: 0.8445 - val_loss: 0.7098 - val_accuracy: 0.6901\n",
      "Epoch 21/25\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.3281 - accuracy: 0.8587 - val_loss: 0.7568 - val_accuracy: 0.6810\n",
      "Epoch 22/25\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.3076 - accuracy: 0.8737 - val_loss: 0.7903 - val_accuracy: 0.6619\n",
      "Epoch 23/25\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.2826 - accuracy: 0.8844 - val_loss: 0.8544 - val_accuracy: 0.6717\n",
      "Epoch 24/25\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.2656 - accuracy: 0.8923 - val_loss: 0.9261 - val_accuracy: 0.6795\n",
      "Epoch 25/25\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.2454 - accuracy: 0.9042 - val_loss: 0.9499 - val_accuracy: 0.6740\n"
     ]
    }
   ],
   "source": [
    "model = model_cnn(500)\n",
    "history = model.fit(X_train.reshape([-1,n_features,1]),y_train,\n",
    "                    validation_data=(X_val.reshape([-1,n_features,1]),y_val),batch_size=256,epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe99a5c",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 10,
     "id": "1fe99a5c",
     "kernelId": "3e6e40d8-69f5-4d5b-bd6d-76c6f49146ca"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.79      0.76      2639\n",
      "           1       0.52      0.45      0.48      1333\n",
      "\n",
      "    accuracy                           0.67      3972\n",
      "   macro avg       0.63      0.62      0.62      3972\n",
      "weighted avg       0.66      0.67      0.67      3972\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_val_p = model.predict(X_val)\n",
    "y_val_p = np.round(y_val_p).flatten()\n",
    "print(classification_report(y_val, y_val_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c53c152",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 11,
     "id": "6c53c152",
     "kernelId": "3e6e40d8-69f5-4d5b-bd6d-76c6f49146ca"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6739677744209466\n",
      "Precision: 0.5164644714038128\n",
      "Recall: 0.44711177794448614\n",
      "F1 score: 0.4792923200643346\n"
     ]
    }
   ],
   "source": [
    "print_metrics(y_val, y_val_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43f0e6b",
   "metadata": {},
   "source": [
    "## Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38aea61a-8223-4f7b-b89e-5febfe238beb",
   "metadata": {
    "gradient": {
     "execution_count": 12,
     "id": "38aea61a-8223-4f7b-b89e-5febfe238beb",
     "kernelId": "3e6e40d8-69f5-4d5b-bd6d-76c6f49146ca"
    }
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"data/OLIDv1/testset-levela.tsv\", sep='\\t').set_index('id')\n",
    "y_test = pd.read_csv(\"data/OLIDv1/labels-levela.csv\", names = ['id','subtask_a']).set_index('id')\n",
    "df_test = df_test.join(y_test).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800ebe6f-6d60-4052-b472-68f68e7e5346",
   "metadata": {
    "gradient": {
     "execution_count": 13,
     "id": "800ebe6f-6d60-4052-b472-68f68e7e5346",
     "kernelId": "3e6e40d8-69f5-4d5b-bd6d-76c6f49146ca"
    }
   },
   "outputs": [],
   "source": [
    "x_test = df_test.tweet\n",
    "y_test = df_test.subtask_a.apply(lambda x: 1 if x=='OFF' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862752e1-10cc-4bf1-a850-357af61bdc0d",
   "metadata": {
    "gradient": {
     "execution_count": 14,
     "id": "862752e1-10cc-4bf1-a850-357af61bdc0d",
     "kernelId": "3e6e40d8-69f5-4d5b-bd6d-76c6f49146ca"
    }
   },
   "outputs": [],
   "source": [
    "data_test = [preprocess(tweet) for tweet in x_test]\n",
    "X_test = vectorizer.transform(data_test)\n",
    "X_test = X_test.toarray().reshape([-1,n_features,1])\n",
    "y_test_p = model.predict(X_test)\n",
    "y_test_p = np.round(y_test_p).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881240b1",
   "metadata": {
    "gradient": {
     "execution_count": 15,
     "id": "881240b1",
     "kernelId": "3e6e40d8-69f5-4d5b-bd6d-76c6f49146ca"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81       620\n",
      "           1       0.48      0.42      0.45       240\n",
      "\n",
      "    accuracy                           0.71       860\n",
      "   macro avg       0.63      0.62      0.63       860\n",
      "weighted avg       0.70      0.71      0.71       860\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_test_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d452ab",
   "metadata": {
    "gradient": {
     "id": "67d452ab",
     "kernelId": "3e6e40d8-69f5-4d5b-bd6d-76c6f49146ca"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
